[
  {
    "objectID": "sessions/index.html",
    "href": "sessions/index.html",
    "title": "Content",
    "section": "",
    "text": "Week 1 - Introduction to RMDA\n\n\n\n\n\n\nFelipe Melo\n\n\nApr 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2 - Data Wrangling & Research Questions\n\n\n\n\n\n\nFelipe Melo\n\n\nApr 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3 - Data Visualisation & Scientific Hypotheses\n\n\n\n\n\n\nFelipe Melo\n\n\nApr 19, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "RM&DA Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester!\n\nGet-started  Here is where you should start your journey. This is a short introduction to R and RStudio.\nContent  All the lessons live here, grouped by weeks.\n\n[Preparation] - Every week starts here with a few steps to set up the basics in terms of packages and readings.\n[Session] - Here you’ll find the slides and recorded videos focused on the core learning outcomes\n[Exercise] - This is your post-sesssion, auto-learning hours of study and must be organized in your Quarto workbook.\n\n\n\n\n\n\ntl;dr: You should follow this general process for each week:\n\nDo everything on the preparation section ()\nWatch the recorded videos and check the slides of the lesson ()\nComplete the exercise () using your quarto workbook () and submit it to the respective Dropbox"
  },
  {
    "objectID": "schedule.html#schedule",
    "href": "schedule.html#schedule",
    "title": "RM&DA Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester!\n\nGet-started  Here is where you should start your journey. This is a short introduction to R and RStudio.\nContent  All the lessons live here, grouped by weeks.\n\n[Preparation] - Every week starts here with a few steps to set up the basics in terms of packages and readings.\n[Session] - Here you’ll find the slides and recorded videos focused on the core learning outcomes\n[Exercise] - This is your post-sesssion, auto-learning hours of study and must be organized in your Quarto workbook.\n\n\n\n\n\n\ntl;dr: You should follow this general process for each week:\n\nDo everything on the preparation section ()\nWatch the recorded videos and check the slides of the lesson ()\nComplete the exercise () using your quarto workbook () and submit it to the respective Dropbox"
  },
  {
    "objectID": "get-started/1-install.html",
    "href": "get-started/1-install.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "Artwork by @allison_horst"
  },
  {
    "objectID": "get-started/1-install.html#video-tutorials",
    "href": "get-started/1-install.html#video-tutorials",
    "title": "Installing R and RStudio",
    "section": "Video Tutorials",
    "text": "Video Tutorials"
  },
  {
    "objectID": "sessions/week1/1-intro.html",
    "href": "sessions/week1/1-intro.html",
    "title": "Week 1 - Introduction to RMDA",
    "section": "",
    "text": "Today you are going to understand how this modules works."
  },
  {
    "objectID": "sessions/week1/1-intro.html#slides",
    "href": "sessions/week1/1-intro.html#slides",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Slides",
    "text": "Slides\n    View slides in full screen"
  },
  {
    "objectID": "sessions/week1/1-intro.html#videos",
    "href": "sessions/week1/1-intro.html#videos",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Videos",
    "text": "Videos"
  },
  {
    "objectID": "sessions/week1/1-intro.html#exercise-1---create-your-workbook",
    "href": "sessions/week1/1-intro.html#exercise-1---create-your-workbook",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Exercise 1 - Create your workbook",
    "text": "Exercise 1 - Create your workbook"
  },
  {
    "objectID": "sessions/week1/1-intro.html#introduction",
    "href": "sessions/week1/1-intro.html#introduction",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Introduction",
    "text": "Introduction\nQuarto is a powerful tool for creating dynamic documents and websites. This tutorial will guide you through the process of creating a simple webpage using Quarto."
  },
  {
    "objectID": "sessions/week1/1-intro.html#prerequisites",
    "href": "sessions/week1/1-intro.html#prerequisites",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore you begin, make sure you have the following installed:\n\nQuarto: You can download and install Quarto from quarto.org.\nRstudio: However, any text editor will work, such as VS Code, Sublime Text, or Notepad++.\n\n\nStep 1: Create a New Quarto Document\n\nOpen your terminal or command prompt.\nNavigate to the directory where you want to create your webpage.\nRun the following command to create a new Quarto document:\nquarto create webpage.qmd\nThis command creates a file named webpage.qmd.\n\n\n\nStep 2: Edit the Quarto Document\n\nOpen webpage.qmd in your text editor.\nYou’ll see some default content, including a title and some example text.\nModify the content to create your webpage. For example:\n---\ntitle: \"My First Quarto Webpage\"\nformat: html\n---\n\n## Welcome!\n\nThis is my first webpage created with Quarto.\n\nHere's a simple list:\n\n* Item 1\n* Item 2\n* Item 3\n\nYou can also include code blocks:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"Hello, Quarto!\")\n\n[1] \"Hello, Quarto!\"\n\n:::\nAnd mathematical equations:\n\\[\nE = mc^2\n\\]\nYou can add images too:\n\nknitr::include_graphics(\"https://quarto.org/quarto.png\")\n\n\n\n\n\n\n\n\n```\nExplanation of the code:\n\n--- title: \"My First Quarto Webpage\" format: html --- : This is the YAML header, which sets the title of your webpage and specifies the output format (HTML in this case).\n## Welcome! : This is a level 2 heading.\n* Item 1 : This creates a bulleted list.\n```{r}: This begins a R code block.\n$$E = mc^2$$: This inserts a LaTeX equation.\n```{r}: This begins an R code block.\nknitr::include_graphics(\"https://quarto.org/quarto.png\"): This includes an image from a URL.\n\n\n\n\nStep 3: Render the Webpage\n\nIn your terminal or command prompt, navigate to the directory containing webpage.qmd.\nRun the following command to render the webpage:\nquarto render webpage.qmd\nThis command will create an HTML file named webpage.html in the same directory.\n\n\n\nStep 4: View the Webpage\n\nOpen webpage.html in your web browser.\nYou should see your webpage with the content you created."
  },
  {
    "objectID": "sessions/week1/1-intro.html#adding-more-content",
    "href": "sessions/week1/1-intro.html#adding-more-content",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Adding more content",
    "text": "Adding more content\nYou can add more content to your webpage by editing webpage.qmd. Quarto supports various types of content, including:\n\nHeadings: Use #, ##, ###, etc. for different heading levels.\nParagraphs: Just type your text.\nLists: Use * or - for unordered lists, and 1., 2., etc. for ordered lists.\nCode Blocks: Use ```{language} to insert code blocks.\nMathematical Equations: Use $$ for LaTeX equations.\nImages: Use ![alt text](path/to/image.png) or {r} knitr::include_graphics(\"path/to/image.png\").\nLinks: Use [link text](url).\nTables: Use Markdown table syntax."
  },
  {
    "objectID": "sessions/week1/1-intro.html#further-exploration",
    "href": "sessions/week1/1-intro.html#further-exploration",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Further Exploration",
    "text": "Further Exploration\n\nExplore the Quarto documentation for more advanced features: quarto.org.\nExperiment with different output formats, such as PDF or Word.\nLearn about Quarto projects for creating multi-page websites.\nLook into adding CSS and Javascript for styling and interactivity."
  },
  {
    "objectID": "sessions/week1/1-intro.html#publishing-to-quarto-pub",
    "href": "sessions/week1/1-intro.html#publishing-to-quarto-pub",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Publishing to Quarto Pub",
    "text": "Publishing to Quarto Pub\nKnow how to publish your Quarto webpage to Quarto Pub, making it accessible online."
  },
  {
    "objectID": "sessions/week1/1-intro.html#prerequisites-1",
    "href": "sessions/week1/1-intro.html#prerequisites-1",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nAll the prerequisites from the previous tutorial.\nA Quarto Pub account. You can create one at quarto.pub.\n\n\nStep 1: Create a Quarto Webpage (If you haven’t already)\nIf you haven’t already created a Quarto webpage, follow the steps in the previous tutorial to create webpage.qmd and render it into webpage.html.\n\n\nStep 2: Initialize Quarto Pub\n\nOpen your terminal or command prompt.\nNavigate to the directory containing webpage.qmd.\nRun the following command to initialize Quarto Pub:\nquarto publish quarto-pub\nThis command will prompt you to log in to your Quarto Pub account. Follow the instructions to authenticate.\n\n\n\nStep 3: Publish Your Webpage\n\nAfter successful authentication, Quarto will detect the webpage.html file and ask you if you want to publish it.\nConfirm that you want to publish the webpage.\nQuarto will upload your webpage to Quarto Pub.\nYou’ll receive a URL where your webpage is hosted.\n\n\n\nStep 4: View Your Published Webpage\n\nOpen the URL provided by Quarto in your web browser.\nYou should see your webpage hosted on Quarto Pub.\n\n\n\nStep 5: Updating your published page.\nIf you edit the webpage.qmd file, you will need to re-render the html file, and then republish.\n\nEdit webpage.qmd with your text editor.\nRender the html file again.\nquarto render webpage.qmd\nRepublish the webpage.\nquarto publish quarto-pub\nQuarto Pub will update the existing webpage with the new content."
  },
  {
    "objectID": "sessions/week1/1-intro.html#important-considerations",
    "href": "sessions/week1/1-intro.html#important-considerations",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Important Considerations",
    "text": "Important Considerations\n\nFile Organization: For more complex websites, consider creating a Quarto project. This will help you organize your files and manage your website more effectively.\nCustom Domains: Quarto Pub allows you to use custom domains for your websites. Refer to the Quarto Pub documentation for instructions.\nSecurity: Be mindful of the content you publish online. Avoid sharing sensitive information.\nQuarto Pub Limitations: Quarto Pub has some limitations, especially for large or complex websites. For more advanced hosting options, consider using other platforms like Netlify or GitHub Pages.\nFree tier limitations: The free tier of Quarto Pub has some limitations, regarding the number of deployments, and storage. Refer to the Quarto Pub documentation for the most up to date limitations."
  },
  {
    "objectID": "sessions/week1/1-intro.html#further-exploration-1",
    "href": "sessions/week1/1-intro.html#further-exploration-1",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Further Exploration",
    "text": "Further Exploration\n\nExplore the Quarto Pub documentation for more advanced features: quarto.pub.\nLearn about Quarto projects for creating multi-page websites.\nExperiment with different Quarto Pub settings and options."
  },
  {
    "objectID": "sessions/week1/1-intro.html#exercise-1",
    "href": "sessions/week1/1-intro.html#exercise-1",
    "title": "Week 1 - Introduction to RMDA",
    "section": "Exercise",
    "text": "Exercise\nNow create your own quarto workbook:\n1 - Download the zip file of the project\n2- Tweak the *qmd file as you wish\n3 - Publish your workbook\n4 - Submit to the link to NOW dropbox folder"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html",
    "href": "sessions/week3/3-data_expl.html",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "",
    "text": "Artwork by @allison_horst"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#learning-objectives",
    "href": "sessions/week3/3-data_expl.html#learning-objectives",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\n\nResearch Methods\nData Analyses\n\n\n\n\nDistinguish between scientific and statistical hypotheses\nProduce informative summaries of data\n\n\nElaborate sounding scientific hypotheses\nUnderstand moments of distribution\n\n\n\nBasics of data visualization"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#prerequisites",
    "href": "sessions/week3/3-data_expl.html#prerequisites",
    "title": "Week 3 - Data Exploration & Scientific Hypotheses",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore you begin, ensure you have the following installed:\n\nR: You can download the latest version from the official R website. Instructions for different operating systems (Windows, Mac OS, UNIX/Linux) are available [8]. R must be installed before installing RStudio [9].\nRStudio: Download and install RStudio Desktop from https://www.rstudio.com/ [10]. To open RStudio, locate it in your applications and launch it [11].\ntidyverse package: Install the tidyverse package within R. Open RStudio and in the Console pane, type and run the following command [12]:\ninstall.packages(\"tidyverse\")\n\nThis command needs to be run only the first time you want to use the tidyverse. You can also install packages by navigating to Tools -&gt; Install Packages in RStudio."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#readings",
    "href": "sessions/week3/3-data_expl.html#readings",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "Readings",
    "text": "Readings\nFor Data Analyses\n\n Check chapter 4 of the e-book Tidyverse Skills for Data Science\n Data visualization with ggplot2 :: Cheat Sheet\n Data summaries with dplyr\n\nFor Research Methods\n\n The hypotheses in science writing\n Formulating Hypotheses for Different Study Designs"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#learning-objectives-1",
    "href": "sessions/week3/3-data_expl.html#learning-objectives-1",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDemonstrate how to subset, merge, and create new datasets from existing data structures in R.\nPerform basic data wrangling with functions in the Tidyverse package."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#tidyverse-basics",
    "href": "sessions/week3/3-data_expl.html#tidyverse-basics",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "Tidyverse basics",
    "text": "Tidyverse basics\nThe Tidyverse suite of packages introduces users to a set of data structures, functions and operators to make working with data more intuitive, but is slightly different from the way we do things in base R. Two important new concepts we will focus on are pipes and tibbles.\nBefore we get started with pipes or tibbles, let’s load the library:\nlibrary(tidyverse)\n\nPipes\nStringing together commands in R can be quite daunting. Also, trying to understand code that has many nested functions can be confusing.\nTo make R code more human readable, the Tidyverse tools use the pipe, %&gt;%, which was acquired from the magrittr package and is now part of the dplyr package that is installed automatically with Tidyverse. The pipe allows the output of a previous command to be used as input to another command instead of using nested functions.\n\nNOTE: Shortcut to write the pipe is shift + command/ctrl + M\n\nAn example of using the pipe to run multiple commands:\n## A single command\nsqrt(83)\n\n## Base R method of running more than one command\nround(sqrt(83), digits = 2)\n\n## Running more than one command with piping\nsqrt(83) %&gt;% round(digits = 2)\nThe pipe represents a much easier way of writing and deciphering R code, and so we will be taking advantage of it, when possible, as we work through the remaining lesson.\n\nExercises\n\nCreate a vector of random numbers using the code below:\nrandom_numbers &lt;- c(81, 90, 65, 43, 71, 29)\nUse the pipe (%&gt;%) to perform two steps in a single line:\n\nTake the mean of random_numbers using the mean() function.\nRound the output to three digits using the round() function.\n\n\n\n\n\nTibbles\nA core component of the tidyverse is the tibble. Tibbles are a modern rework of the standard data.frame, with some internal improvements to make code more reliable. They are data frames, but do not follow all of the same rules. For example, tibbles can have numbers/symbols for column names, which is not normally allowed in base R.\nImportant: tidyverse is very opininated about row names. These packages insist that all column data (e.g. data.frame) be treated equally, and that special designation of a column as rownames should be deprecated. Tibble provides simple utility functions to handle rownames: rownames_to_column() and column_to_rownames().\nTibbles can be created directly using the tibble() function or data frames can be converted into tibbles using as_tibble(name_of_df).\n\nNOTE: The function as_tibble() will ignore row names, so if a column representing the row names is needed, then the function rownames_to_column(name_of_df) should be run prior to turning the data.frame into a tibble. Also, as_tibble() will not coerce character vectors to factors by default."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#experimental-data",
    "href": "sessions/week3/3-data_expl.html#experimental-data",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "Experimental data",
    "text": "Experimental data\nWe’re going to explore the Tidyverse suite of tools to wrangle our data to prepare it for visualization. You should have downloaded the file called gprofiler_results_Mov10oe.tsv into your R project’s data folder earlier.\n\nIf you do not have the gprofiler_results_Mov10oe.tsv file in your data folder, you can right click and download it into the data folder using this link.\n\nThe dataset:\n\nRepresents the functional analysis results, including the biological processes, functions, pathways, or conditions that are over-represented in a given list of genes.\nOur gene list was generated by differential gene expression analysis and the genes represent differences between control mice and mice over-expressing a gene involved in RNA splicing.\n\nThe functional analysis that we will focus on involves gene ontology (GO) terms, which:\n\ndescribe the roles of genes and gene products\norganized into three controlled vocabularies/ontologies (domains):\n\nbiological processes (BP)\ncellular components (CC)\nmolecular functions (MF)"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#analysis-goal-and-workflow",
    "href": "sessions/week3/3-data_expl.html#analysis-goal-and-workflow",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "Analysis goal and workflow",
    "text": "Analysis goal and workflow\nGoal: Visually compare the most significant biological processes (BP) based on the number of associated differentially expressed genes (gene ratios) and significance values by creating the following plot:\n\n\n\ndotplot6\n\n\nTo wrangle our data in preparation for the plotting, we are going to use the Tidyverse suite of tools to wrangle and visualize our data through several steps:\n\nRead in the functional analysis results\nExtract only the GO biological processes (BP) of interest\nSelect only the columns needed for visualization\nOrder by significance (p-adjusted values)\nRename columns to be more intuitive\nCreate additional metrics for plotting (e.g. gene ratios)\nPlot results"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#tidyverse-tools",
    "href": "sessions/week3/3-data_expl.html#tidyverse-tools",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "Tidyverse tools",
    "text": "Tidyverse tools\nWhile all of the tools in the Tidyverse suite are deserving of being explored in more depth, we are going to investigate more deeply the reading (readr), wrangling (dplyr), and plotting (ggplot2) tools."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#read-in-the-functional-analysis-results",
    "href": "sessions/week3/3-data_expl.html#read-in-the-functional-analysis-results",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "1. Read in the functional analysis results",
    "text": "1. Read in the functional analysis results\nWhile the base R packages have perfectly fine methods for reading in data, the readr and readxl Tidyverse packages offer additional methods for reading in data. Let’s read in our tab-delimited functional analysis results using read_delim():\n# Read in the functional analysis results\nfunctional_GO_results &lt;- read_delim(file = \"data/gprofiler_results_Mov10oe.tsv\", delim = \"\\t\" )\n\n# Take a look at the results\nfunctional_GO_results\n\n\nClick here to see how to do this in base R\n\n\n# Read in the functional analysis results\nfunctional_GO_results &lt;- read.delim(file = \"data/gprofiler_results_Mov10oe.tsv\", sep = \"\\t\" )\n# Take a look at the results\nfunctional_GO_results\n\n\nNotice that the results were automatically read in as a tibble and the output gives the number of rows, columns and the data type for each of the columns.\n\nNOTE: A large number of tidyverse functions will work with both tibbles and dataframes, and the data structure of the output will be identical to the input. However, there are some functions that will return a tibble (without row names), whether or not a tibble or dataframe is provided."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#extract-only-the-go-biological-processes-bp-of-interest",
    "href": "sessions/week3/3-data_expl.html#extract-only-the-go-biological-processes-bp-of-interest",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "2. Extract only the GO biological processes (BP) of interest",
    "text": "2. Extract only the GO biological processes (BP) of interest\nNow that we have our data, we will need to wrangle it into a format ready for plotting. For all of our data wrangling steps we will be using tools from the dplyr package, which is a swiss-army knife for data wrangling of data frames.\nTo extract the biological processes of interest, we only want those rows where the domain is equal to BP, which we can do using the filter() function.\nTo filter rows of a data frame/tibble based on values in different columns, we give a logical expression as input to the filter() function to return those rows for which the expression is TRUE.\nNow let’s return only those rows that have a domain of BP:\n# Return only GO biological processes\nbp_oe &lt;- functional_GO_results %&gt;%\n  filter(domain == \"BP\")\n  \nView(bp_oe)\n\n\nClick here to see how to do this in base R\n\n\n# Return only GO biological processes\nidx &lt;- functional_GO_results$domain == \"BP\"\nbp_oe2 &lt;- functional_GO_results[idx,]\nView(bp_oe)\n\n\nNow we have returned only those rows with a domain of BP. How have the dimensions of our results changed?\n\nExercise:\nWe would like to perform an additional round of filtering to only keep the most specific GO terms.\n\nFor bp_oe, use the filter() function to only keep those rows where the relative.depth is greater than 4.\nSave output to overwrite our bp_oe variable."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#select-only-the-columns-needed-for-visualization",
    "href": "sessions/week3/3-data_expl.html#select-only-the-columns-needed-for-visualization",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "3. Select only the columns needed for visualization",
    "text": "3. Select only the columns needed for visualization\nFor visualization purposes, we are only interested in the columns related to the GO terms, the significance of the terms, and information about the number of genes associated with the terms.\nTo extract columns from a data frame/tibble we can use the select() function. In contrast to base R, we do not need to put the column names in quotes for selection.\n# Selecting columns to keep\nbp_oe &lt;- bp_oe %&gt;%\n  select(term.id, term.name, p.value, query.size, term.size, overlap.size, intersection)\n\nView(bp_oe)\n\n\nClick here to see how to do this in base R\n\n\n# Selecting columns to keep\nbp_oe &lt;- bp_oe[, c(\"term.id\", \"term.name\", \"p.value\", \"query.size\", \"term.size\", \"overlap.size\", \"intersection\")]\nView(bp_oe)\n\n\nThe select() function also allows for negative selection. So we could have alternately removed columns with negative selection. Note that we need to put the column names inside of the combine (c()) function with a - preceding it for this functionality.\n# DO NOT RUN\n# Selecting columns to remove\nbp_oe &lt;- bp_oe %&gt;%\n    select(-c(query.number, significant, recall, precision, subgraph.number, relative.depth, domain))\n\n\nClick here to see how to do this in base R\n\n\n# DO NOT RUN\n# Selecting columns to remove\nidx &lt;- !(colnames(bp_oe) %in% c(\"query.number\", \"significant\", \"recall\", \"precision\", \"subgraph.number\", \"relative.depth\", \"domain\"))\nbp_oe &lt;- bp_oe[, idx]"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#order-go-processes-by-significance-adjusted-p-values",
    "href": "sessions/week3/3-data_expl.html#order-go-processes-by-significance-adjusted-p-values",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "4. Order GO processes by significance (adjusted p-values)",
    "text": "4. Order GO processes by significance (adjusted p-values)\nNow that we have only the rows and columns of interest, let’s arrange these by significance, which is denoted by the adjusted p-value.\nLet’s sort the rows by adjusted p-value with the arrange() function.\n# Order by adjusted p-value ascending\nbp_oe &lt;- bp_oe %&gt;%\n  arrange(p.value)\n\n\nClick here to see how to do this in base R\n\n\n# Order by adjusted p-value ascending\nidx &lt;- order(bp_oe$p.value)\nbp_oe &lt;- bp_oe[idx,]\n\n\n\nNOTE1: If you wanted to arrange in descending order, then you could have run the following instead:\n# DO NOT RUN\n# Order by adjusted p-value descending\nbp_oe &lt;- bp_oe %&gt;%\n  arrange(desc(p.value))\n\n\nClick here to see how to do this in base R\n\n\n# DO NOT RUN\n# Order by adjusted p-value descending\nidx &lt;- order(bp_oe$p.value, decreasing = TRUE)\nbp_oe &lt;- bp_oe[idx,]\n\n\n\nNOTE2: Ordering variables in ggplot2 is a bit different. This post introduces a few ways of ordering variables in a plot."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#rename-columns-to-be-more-intuitive",
    "href": "sessions/week3/3-data_expl.html#rename-columns-to-be-more-intuitive",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "5. Rename columns to be more intuitive",
    "text": "5. Rename columns to be more intuitive\nWhile not necessary for our visualization, renaming columns more intuitively can help with our understanding of the data using the rename() function. The syntax is new_name = old_name.\nLet’s rename the term.id and term.name columns.\n# Provide better names for columns\nbp_oe &lt;- bp_oe %&gt;% \n  dplyr::rename(GO_id = term.id, \n                GO_term = term.name)\n\n\nClick here to see how to do this in base R\n\n\n# Provide better names for columns\ncolnames(bp_oe)[colnames(bp_oe) == \"term.id\"] &lt;- \"GO_id\"\ncolnames(bp_oe)[colnames(bp_oe) == \"term.name\"] &lt;- \"GO_term\"\n\n\n\nNOTE: In the case of two packages with identical function names, you can use :: with the package name before and the function name after (e.g stats::filter()) to ensure that the correct function is implemented. The :: can also be used to bring in a function from a library without loading it first.\nIn the example above, we wanted to use the rename() function specifically from the dplyr package, and not any of the other packages (or base R) which may have the rename() function.\n\n\nExercise\nRename the intersection column to genes to reflect the fact that these are the DE genes associated with the GO process."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#create-additional-metrics-for-plotting-e.g.-gene-ratios",
    "href": "sessions/week3/3-data_expl.html#create-additional-metrics-for-plotting-e.g.-gene-ratios",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "6. Create additional metrics for plotting (e.g. gene ratios)",
    "text": "6. Create additional metrics for plotting (e.g. gene ratios)\nFinally, before we plot our data, we need to create a couple of additional metrics. The mutate() function enables you to create a new column from an existing column.\nLet’s generate gene ratios to reflect the number of DE genes associated with each GO process relative to the total number of DE genes.\n# Create gene ratio column based on other columns in dataset\nbp_oe &lt;- bp_oe %&gt;%\n  mutate(gene_ratio = overlap.size / query.size)\n\n\nClick here to see how to do this in base R\n\n\n# Create gene ratio column based on other columns in dataset\nbp_oe &lt;- cbind(bp_oe, gene_ratio = bp_oe$overlap.size / bp_oe$query.size)\n\n\n\nExercise\nCreate a column in bp_oe called term_percent to determine the percent of DE genes associated with the GO term relative to the total number of genes associated with the GO term (overlap.size / term.size)\n\nOur final data for plotting should look like the table below:"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#next-steps",
    "href": "sessions/week3/3-data_expl.html#next-steps",
    "title": "Week 4 Data Exploration & Scientific Hypotheses",
    "section": "Next steps",
    "text": "Next steps\nNow that we have our results ready for plotting, we can use the ggplot2 package to plot our results. If you are interested, you can follow this lesson and dive into how to use ggplot2 to create the plots with this dataset.\n\nAdditional resources\n\nR for Data Science\nteach the tidyverse\ntidy style guide\n\n\nThis lesson has been developed by members of the teaching team at the Harvard Chan Bioinformatics Core (HBC). These are open access materials distributed under the terms of the Creative Commons Attribution license (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#research-methods",
    "href": "sessions/week3/3-data_expl.html#research-methods",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "Research Methods",
    "text": "Research Methods"
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#what-is-a-scientific-hypothesis",
    "href": "sessions/week3/3-data_expl.html#what-is-a-scientific-hypothesis",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "What is a scientific hypothesis?",
    "text": "What is a scientific hypothesis?\nAccording to the Britannica, a scientific hypothesis is: “… an idea that proposes a tentative explanation about a phenomenon or a narrow set of phenomena observed in the natural world.”\n\nDeductive reasoning and inductive reasoning are two inseparable but distinct processes within scientific research. They reasonate with each other in a cyclical manner to advance scientific knowledge.\nHere’s how they connect:\nInductive reasoning often initiates the scientific process. It begins with empirical observations of the real world. By noticing patterns in these observations, scientists use inductive reasoning to construct broad generalisations or theories. For example, observing that apples, bananas, and oranges grow on trees might lead to the inductive generalisation that all fruit grows on trees.\nOnce a theory is formulated through inductive reasoning, it then serves as a basis for deductive reasoning. Deductive reasoning starts with a generalisation or hypothesis (derived from the theory) and uses it to reach logical conclusions about the real world. If the hypothesis is correct, then the logical conclusions reached through deductive reasoning should also be correct.\nFor instance, if the theory is that all living things require energy to survive, then deductive reasoning would lead to the conclusion that ducks, being living things, require energy to survive.\nScientists use deductive reasoning to empirically test the hypotheses that are generated from their inductively developed theories. They design studies and experiments to see if their logical conclusions hold true in the real world.\nThe results of these deductive tests then feed back into the scientific process. If the results are consistent with the theory (and thus the hypothesis), the theory is supported. However, if the results are not consistent, the theory may need to be modified and refined, leading to the generation of new hypotheses that will again be tested deductively. This creates a circular process where observations lead to theories (induction), theories lead to testable predictions (hypotheses), and those predictions are tested against further observations (deduction), which in turn can refine the theories. In essence, induction is often about building up from specific observations to broader ideas, while deduction is about breaking down broader ideas into specific, testable predictions. They work together, with inductive reasoning often paving the way for deductive testing, and the outcomes of deductive testing influencing the further development of theories arrived at through induction. Some research approaches, like case studies, lean more heavily on inductive processes, while experimental research often emphasises deductive reasoning.\n\n\n\n\n\n\nTip\n\n\n\nScientists use inductive reasoning to formulate theories, which then lead to hypotheses that are tested using deductive reasoning. In essence, science involves both inductive and deductive processes. Research approaches like case studies, which heavily rely on empirical observations and gathering large amounts of data to find interesting patterns and new ideas, are closely associated with inductive processes."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#research-vs-statistical-hypotheses",
    "href": "sessions/week3/3-data_expl.html#research-vs-statistical-hypotheses",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "Research vs Statistical Hypotheses",
    "text": "Research vs Statistical Hypotheses\n\nA scientific hypothesis is a proposed explanation for an observation, phenomenon, or scientific problem. It must be based on observations and make a testable and reproducible prediction about reality. A scientific hypothesis is a provisional idea whose merit requires evaluation and requires further work to either confirm or disprove it. If repeatedly demonstrated to be true by experiment, a scientific hypothesis may become part of a scientific theory. In its essence, a scientific hypothesis aims to be true, adequate, accurate or useful in explaining some natural phenomenon. It guides the types of data we collect and the analyses we conduct.\nA statistical hypothesis, on the other hand, is specifically used when investigating a possible correlation or similar relation between phenomena. In such cases, the hypothesis that a relation exists is not examined in the same way as a proposed new law of nature. Instead, statistical tests are employed to determine how likely it is that the observed overall effect would occur if the hypothesised relation does not actually exist.\nSome key distinctions are:\n\nScope and Generality: A scientific hypothesis is often a broader proposed explanation, while a statistical hypothesis is a more specific statement about the relationship between variables that is subjected to statistical testing. For instance, a scientific hypothesis might be that “sunlight is necessary for seeds to grow”. A related statistical hypothesis could be that “seeds grown in bags wrapped in aluminium foil will produce shorter plants on average compared to seeds grown in bags not wrapped in foil”.\nMethod of Evaluation: Scientific hypotheses are evaluated through the broader scientific process, which involves observation, experimentation, and analysis. This can include various research approaches. Statistical hypotheses are specifically evaluated using statistical tests. These tests involve comparing a null hypothesis (typically stating no relation) with an alternative hypothesis (stating a relation exists) and determining the likelihood of the observed data under the null hypothesis. A decision is then made based on a pre-determined significance level.\nLevel of Abstraction: Scientific hypotheses often deal with underlying mechanisms or causes of phenomena. Statistical hypotheses are more directly concerned with patterns and relationships within data. The PMC source discusses the TASI model, where statistical assumptions are considered necessary to test an empirical hypothesis which is derived from a theoretical hypothesis using auxiliary assumptions. This highlights that statistical hypotheses are often a step in testing broader scientific ideas.\nForm of Statement: While scientific hypotheses can be verbal or formal (e.g., mathematical models), statistical hypotheses are often formulated in terms of population parameters and distributions, making them amenable to statistical analysis.\n\n\n\n\n\n\n\nNote\n\n\n\nIn summary, a scientific hypothesis proposes an explanation for a phenomenon and guides the research process, while a statistical hypothesis is a specific, testable statement about data relationships derived from a scientific hypothesis, which is evaluated using statistical methods. The statistical hypothesis provides a way to quantitatively assess some aspect of the broader scientific hypothesis."
  },
  {
    "objectID": "example_presentation.html",
    "href": "example_presentation.html",
    "title": "Quiz example",
    "section": "",
    "text": "Bill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google"
  },
  {
    "objectID": "example_presentation.html#a-basic-example",
    "href": "example_presentation.html#a-basic-example",
    "title": "Quiz example",
    "section": "",
    "text": "Bill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google"
  },
  {
    "objectID": "example_presentation.html#a-quiz-with-a-clear-answer-button",
    "href": "example_presentation.html#a-quiz-with-a-clear-answer-button",
    "title": "Quiz example",
    "section": "A quiz with a clear answer button",
    "text": "A quiz with a clear answer button\n\nBill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google\n\n\nClear answer"
  },
  {
    "objectID": "example_presentation.html#a-quiz-with-additional-buttons",
    "href": "example_presentation.html#a-quiz-with-additional-buttons",
    "title": "Quiz example",
    "section": "A quiz with additional buttons",
    "text": "A quiz with additional buttons\n\nBill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google\n\n\nClear answer\n\n\n\n\n\n\n\n\n\n\nShow hint\n\nThe company name starts with an ‘M’…\n\n\n\n\n\n\nShow Answer\n\nBill Gates and Paul Allen founded Microsoft on April 4, 1975."
  },
  {
    "objectID": "example.html",
    "href": "example.html",
    "title": "Quiz example",
    "section": "",
    "text": "This document illustrates the usage of the naquiz quarto extension.\nThe extension enables adding multiple choice questions when using HTML documents. It also adds Alpine.js javascript framework to the document."
  },
  {
    "objectID": "example.html#a-basic-example",
    "href": "example.html#a-basic-example",
    "title": "Quiz example",
    "section": "A basic example",
    "text": "A basic example\n\nBill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google"
  },
  {
    "objectID": "example.html#a-quiz-with-a-clear-answer-button",
    "href": "example.html#a-quiz-with-a-clear-answer-button",
    "title": "Quiz example",
    "section": "A quiz with a clear answer button",
    "text": "A quiz with a clear answer button\n\nBill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google\n\n\nClear answer"
  },
  {
    "objectID": "example.html#a-quiz-with-additional-buttons",
    "href": "example.html#a-quiz-with-additional-buttons",
    "title": "Quiz example",
    "section": "A quiz with additional buttons",
    "text": "A quiz with additional buttons\n\nBill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google\n\n\nClear answer\n\n\n\n\n\n\n\n\n\n\n\nShow hint\n\nThe company name starts with an ‘M’…\n\n\n\n\n\n\nShow Answer\n\nBill Gates and Paul Allen founded Microsoft on April 4, 1975."
  },
  {
    "objectID": "example.html#a-quiz-with-additional-information-in-callouts",
    "href": "example.html#a-quiz-with-additional-information-in-callouts",
    "title": "Quiz example",
    "section": "A quiz with additional information in callouts",
    "text": "A quiz with additional information in callouts\n\nBill Gates was the founder of:\n\n\n\n\n ✗Apple\n\n\n ✓Microsoft\n\n\n ✗Facebook\n\n\n ✗Google\n\n\nClear answer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe company name starts with an ‘M’…\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBill Gates and Paul Allen founded Microsoft on April 4, 1975."
  },
  {
    "objectID": "sessions/week3/3-data_expl.html#what-is-a-scientific-hypothesis-1",
    "href": "sessions/week3/3-data_expl.html#what-is-a-scientific-hypothesis-1",
    "title": "Week 3 - Data Visualisation & Scientific Hypotheses",
    "section": "What is a scientific hypothesis?",
    "text": "What is a scientific hypothesis?"
  },
  {
    "objectID": "assessment.html",
    "href": "assessment.html",
    "title": "Assessment Brief 2025-26",
    "section": "",
    "text": "This Module covers the following courses:\n\nMSc/MRes Applied Ecology & Geospatial Techniques\nMSc/MRes Biodiversity Conservation\nMSc/MRes Endangered Species Recovery & Conservation\nMSc/MRes Equine Performance, Health & Welfare MSc/MRes Smart Agriculture"
  },
  {
    "objectID": "assessment.html#summative-assessment-brief",
    "href": "assessment.html#summative-assessment-brief",
    "title": "Assessment Brief 2025-26",
    "section": "",
    "text": "This Module covers the following courses:\n\nMSc/MRes Applied Ecology & Geospatial Techniques\nMSc/MRes Biodiversity Conservation\nMSc/MRes Endangered Species Recovery & Conservation\nMSc/MRes Equine Performance, Health & Welfare MSc/MRes Smart Agriculture"
  },
  {
    "objectID": "assessment.html#formative-assessments",
    "href": "assessment.html#formative-assessments",
    "title": "Assessment Brief 2025-26",
    "section": "Formative Assessments",
    "text": "Formative Assessments\nYour formative opportunities are related to the development of your workbook and sharing of this development with module leader and colleagues.\n\n\n\n\n\n\nShare your Workbook\n\n\n\nYou must not be shy or embarrassed to share your workbook. Nobody will judge you. We are all learning!"
  },
  {
    "objectID": "assessment.html#type-of-assessment",
    "href": "assessment.html#type-of-assessment",
    "title": "Assessment Brief 2025-26",
    "section": "Type of Assessment",
    "text": "Type of Assessment\nYour Summative is to produce an “article-like” dynamic document containing an analytical workflow for a given dataset where critically interpret the results and draw your conclusions.\n\nStep 1 - Context\nYou will be given a context of a scientific problem. This context will introduce you to a real-world problem that is going to be used as a background for the data that you are going to analyse.\n\n\nStep 2 - The dataset\nYou will have access to a pre-built dataset in a .csv format that will contain all the data and metadata needed for your analyses. The data is the same for everyone and I am not providing data on your specific subject of studies.\n\n\nStep 3 - Your Workbook\nYou are going to work on the assessment using your Quarto workbook constructed over the course of the whole module. This is going to be your submission. I’ll collect your exams using a NOW Dropbox where you can paste the link to your published workbook.\n\n\n\n\n\n\nNote\n\n\n\nThe dataset and context description for the Summative exam will be shared by the end of the module sessions (probably in the last week of classes)."
  },
  {
    "objectID": "assessment.html#transferable-skills-developed-in-this-assessment",
    "href": "assessment.html#transferable-skills-developed-in-this-assessment",
    "title": "Assessment Brief 2025-26",
    "section": "Transferable skills developed in this assessment",
    "text": "Transferable skills developed in this assessment\n\nAnalytical workflow\n\nCreate and attach to an analytical workflow that is reproducible\nGenerate good quality graphs and tables\nComment and understand R code\nIdentify core results within a set of exploratory analyses.\nInterpret and generate conclusions based on data analysed"
  },
  {
    "objectID": "assessment.html#specific-tasks",
    "href": "assessment.html#specific-tasks",
    "title": "Assessment Brief 2025-26",
    "section": "Specific tasks",
    "text": "Specific tasks\n\nDesign an experimental design\nDescribe methods for reproducibility\nCreate a analytical workflow\nComment on the R codes in your workbook"
  },
  {
    "objectID": "assessment.html#assessment-guidance",
    "href": "assessment.html#assessment-guidance",
    "title": "Assessment Brief 2025-26",
    "section": "Assessment Guidance",
    "text": "Assessment Guidance\n\nAnalytical workflow (15%)\nR code commented (15%)\nExploratory analysis (20%)\nQuality graphs and tables (25%)\nInterpretation of results (25%)"
  },
  {
    "objectID": "assessment.html#further-information",
    "href": "assessment.html#further-information",
    "title": "Assessment Brief 2025-26",
    "section": "Further information",
    "text": "Further information\n\nExtenuating circumstances"
  },
  {
    "objectID": "assessment.html#grading-matrix",
    "href": "assessment.html#grading-matrix",
    "title": "Assessment Brief 2025-26",
    "section": "Grading Matrix",
    "text": "Grading Matrix\n\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nFail\nLow | Mid\nMarginal Fail\nPass\nLow | Mid | High\nCommendation\nLow | Mid | High\nDistinction\nLow | Mid |High\nDistinction\nExceptional\n\n\n\n\nAnalytical workflow\nNo clear analytical workflow\nWorkflow not easy to find; mixed analytical approach in search for any significant p-value\nWorkflow relatively reasonable but with excess of flaw analyses and lack of a logic sequence that goes from 1) preparation; 2) data wrangling; 3) Exploratory analyses; 4) Core analyses\nClear workflow but hard to reproduce because crucial steps were either omitted or non commented.\nVery good workflow with clear guidance for reproducibility\nHigh quality workflow, fully reproducible and extensively commented\n\n\nR code commented\nLittle to no comments on coding\nComments provided but non meaningful for crucial steps\nCodes mostly commented but crucial steps are not udnerstood\nCodes mostly commented and helping reproducibility.\nCodes fully commented but not excessively, avoiding visual pollution\nCodes fully commented and not affecting visual inspection of the script and allows full reproducibility and explanation in key steps\n\n\nExploratory analysis\nNo exploratory analyses done\nInsufficient exploratory analyses\nEnough exploratory analyses but not commented or justified\nGood exploratory analyses but poorly commented and little justified\nVery good exploratory analyses, commented and justified\nWorld-class and fully justified exploratory approach to data\n\n\nQuality graphs and tables\nPoor graphs, lacking crucial elements such as axis title and captions\nPoor graphs and tables with some elements present but poorly explained while other elements are missig\nGraphs and tables present with most elements, but some missing components preclude full understanding of the info presented\nGraphs and tables of acceptable quality with all elements present but not clearly descripted\nGood quality graphs and tables that could be accepted for publication in any serious scientific journal\nOutstading graphs and tables with graphical abstracts and schematic figures. All elements present and fully explained.\n\n\nInterpretation of results\nPoor or inexistant critical interpretation of the results found\nDeficient interpretation of the results and misuse of statistical concepts and wrong translation of tests and graphs\nResults are just reported with no critical interpretation or further discussion\nResults correctly reported and critically interpreted but excessive speculation is present\nResults are fully reported in a correct manner with string attachment to the proposed workflow and are discussed without much speculation\nExcellent interpretation, creative and fully connected with scientific hypotheses"
  }
]