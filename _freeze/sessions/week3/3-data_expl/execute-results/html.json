{
  "hash": "810bd354a149be7079ba9ca62ffa9dad",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 3 - Data Visualisation & Scientific Hypotheses\"\nsubtitle: \"RMDA ARES40011\"\nauthor: \"Felipe Melo\"\ndate: \"last-modified\"\ndate-format: \"long\"\nfilters:\n  - naquiz\nformat:\n  html:\n    toc: true\n    toc-expanded: 3\n---\n\n\n\n![](/img/we_believe.png){width=\"500\"}\n\n[Artwork by \\@allison_horst](https://twitter.com/allison_horst){style=\"text-align: center\"}\n\n# Preparation\n\n## Learning objectives\n\n| Research Methods | Data Analyses |\n|------------------------------------|------------------------------------|\n| Distinguish between scientific and statistical hypotheses | Produce informative summaries of data |\n| Elaborate sounding scientific hypotheses | Understand moments of distribution |\n|  | Basics of data visualization |\n\n## Readings\n\n**For Data Analyses**\n\n-   {{< fa book >}} Check chapter 4 of the e-book [Tidyverse Skills for Data Science](https://jhudatascience.org/tidyversecourse/dataviz.html#about-this-course-3)\n-   {{< fa tools >}} [Data visualization with ggplot2 :: Cheat Sheet](https://rstudio.github.io/cheatsheets/html/data-visualization.html)\n-   {{< fa tools >}} [Data summaries with dplyr](https://carpentries-incubator.github.io/r-tidyverse-4-datasets/07-data-summaries.html)\n\n**For Research Methods**\n\n-   {{< fa book >}} [The hypotheses in science writing](https://berks.psu.edu/sites/berks/files/campus/HypothesisHandout_Final.pdf)\n\n-   {{< fa book >}} [Formulating Hypotheses for Different Study Designs](https://pmc.ncbi.nlm.nih.gov/articles/PMC8728594/)\n\n# Lesson\n\n## Part 1\n## What is a scientific hypothesis?\n\nAccording to the Britannica, a [scientific hypothesis](https://www.britannica.com/science/scientific-hypothesis) is: \"... an idea that proposes a tentative explanation about a phenomenon or a narrow set of phenomena observed in the natural world.\"\n\n![](/img/hypothesis.webp)\n\n**Deductive reasoning and inductive reasoning** are two inseparable but distinct processes within scientific research. They reasonate with each other in a cyclical manner to advance scientific knowledge.\n\nHere's how they connect:\n\n**Inductive reasoning** often initiates the scientific process. It begins with empirical observations of the real world. By noticing patterns in these observations, scientists use inductive reasoning to construct broad generalisations or theories. For example, observing that apples, bananas, and oranges grow on trees might lead to the inductive generalisation that all fruit grows on trees.\n\nOnce a **theory** is formulated through inductive reasoning, it then serves as a basis for **deductive reasoning**. Deductive reasoning starts with a generalisation or hypothesis (derived from the theory) and uses it to reach logical conclusions about the real world. If the hypothesis is correct, then the logical conclusions reached through deductive reasoning should also be correct. \n\nFor instance, if the theory is that all living things require energy to survive, then deductive reasoning would lead to the conclusion that ducks, being living things, require energy to survive.\n\nScientists use deductive reasoning to empirically test the hypotheses that are generated from their inductively developed theories. They design studies and experiments to see if their logical conclusions hold true in the real world.\n\nThe results of these deductive tests then feed back into the scientific process. If the results are consistent with the theory (and thus the hypothesis), the theory is supported. However, if the results are not consistent, the theory may need to be modified and refined, leading to the generation of new hypotheses that will again be tested deductively. This creates a circular process where observations lead to theories (**induction**), theories lead to testable predictions (**hypotheses**), and those predictions are tested against further observations (**deduction**), which in turn can refine the theories.\nIn essence, induction is often about building up from specific observations to broader ideas, while deduction is about breaking down broader ideas into specific, testable predictions. They work together, with inductive reasoning often paving the way for deductive testing, and the outcomes of deductive testing influencing the further development of theories arrived at through induction. Some research approaches, like case studies, lean more heavily on inductive processes, while experimental research often emphasises deductive reasoning.\n\n:::{.callout-tip}\nScientists use inductive reasoning to formulate theories, which then lead to hypotheses that are tested using deductive reasoning. In essence, science involves both inductive and deductive processes. Research approaches like case studies, which heavily rely on empirical observations and gathering large amounts of data to find interesting patterns and new ideas, are closely associated with inductive processes.\n:::\n\n## Research vs Statistical Hypotheses\n![](/img/null_vs_stat.png)\n\nA **scientific hypothesis** is a proposed explanation for an observation, phenomenon, or scientific problem. It must be based on observations and make a testable and reproducible prediction about reality. A scientific hypothesis is a provisional idea whose merit requires evaluation and requires further work to either confirm or disprove it. If repeatedly demonstrated to be true by experiment, a scientific hypothesis may become part of a scientific theory. In its essence, a scientific hypothesis aims to be true, adequate, accurate or useful in explaining some natural phenomenon. It guides the types of data we collect and the analyses we conduct.\n\nA **statistical hypothesis**, on the other hand, is specifically used when investigating a possible correlation or similar relation between phenomena. In such cases, the hypothesis that a relation exists is not examined in the same way as a proposed new law of nature. Instead, statistical tests are employed to determine how likely it is that the observed overall effect would occur if the hypothesised relation does not actually exist.\n\nSome key distinctions are:\n\n- Scope and Generality: A scientific hypothesis is often a broader proposed explanation, while a statistical hypothesis is a more specific statement about the relationship between variables that is subjected to statistical testing. For instance, a scientific hypothesis might be that \"sunlight is necessary for seeds to grow\". A related statistical hypothesis could be that \"seeds grown in bags wrapped in aluminium foil will produce shorter plants on average compared to seeds grown in bags not wrapped in foil\".\n\n- Method of Evaluation: Scientific hypotheses are evaluated through the broader scientific process, which involves observation, experimentation, and analysis. This can include various research approaches. Statistical hypotheses are specifically evaluated using statistical tests. These tests involve comparing a null hypothesis (typically stating no relation) with an alternative hypothesis (stating a relation exists) and determining the likelihood of the observed data under the null hypothesis. A decision is then made based on a pre-determined significance level.\n\n- Level of Abstraction: Scientific hypotheses often deal with underlying mechanisms or causes of phenomena. Statistical hypotheses are more directly concerned with patterns and relationships within data. The PMC source discusses the TASI model, where statistical assumptions are considered necessary to test an empirical hypothesis which is derived from a theoretical hypothesis using auxiliary assumptions. This highlights that statistical hypotheses are often a step in testing broader scientific ideas.\n\n- Form of Statement: While scientific hypotheses can be verbal or formal (e.g., mathematical models), statistical hypotheses are often formulated in terms of population parameters and distributions, making them amenable to statistical analysis.\n\n:::callout-note\nIn summary, a scientific hypothesis proposes an explanation for a phenomenon and guides the research process, while a statistical hypothesis is a specific, testable statement about data relationships derived from a scientific hypothesis, which is evaluated using statistical methods. The statistical hypothesis provides a way to quantitatively assess some aspect of the broader scientific hypothesis.\n:::\n\n## Part 2\n\n## Data summarisation with dplyr\n\nData summarisation is a crucial step in understanding your data. It involves calculating descriptive statistics and creating summary tables to get an overview of the dataset, identify patterns, and spot potential issues. The **dplyr** package within the tidyverse provides a set of intuitive functions for efficient data manipulation, including powerful tools for summarisation. **The tidyverse expands the vocabulary of R**.\n\nTo begin, we first need to load the **tidyverse** package, which includes **dplyr**:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the tidyverse package [5, 6]\nlibrary(tidyverse)\n```\n:::\n\n\n\n## Summary Statistics for Ungrouped Data\n\nThe summarise() function in dplyr is used to compute summary statistics for your data1 .... When applied to an ungrouped data frame, it calculates the specified summaries across all rows1 .\n\nLet's use the built-in `iris` dataset as an example :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert the iris dataset to a tibble\nmy_data <- as_tibble(iris)\nmy_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 150 Ã— 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# â„¹ 140 more rows\n```\n\n\n:::\n:::\n\n\n\nWe can compute the mean of Sepal.Length and Petal.Length, as well as the total number of observations using summarise() and the n() function1:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate summary statistics for the entire dataset\nmy_data %>%\n  summarise(\n    count = n(), # Count the number of rows [7, 8]\n    mean_sep_length = mean(Sepal.Length, na.rm = TRUE), # Calculate the mean of Sepal.Length, removing NA values [6]\n    mean_pet_length = mean(Petal.Length, na.rm = TRUE)  # Calculate the mean of Petal.Length, removing NA values [6]\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  count mean_sep_length mean_pet_length\n  <int>           <dbl>           <dbl>\n1   150            5.84            3.76\n```\n\n\n:::\n:::\n\n\n\nThe `na.rm = TRUE` argument is used to handle missing values by removing them before computing the mean5 . R is clear about trying to do calculations when there is an NA5 . If there is an NA, it cannot create a correct calculation, so it will return NA again5 . This is a nice way of quickly seeing that you have missing values in your data5 \n## Summary Statistics for Grouped Data\n\nOften, we want to compute summary statistics for different groups within our data. This is This is achieved by using the `group_by()` function before `summarise()` `group_by()` takes one or more column names as arguments and groups the data based on the unique values in those columns. Subsequent `summarise()` operations will then be performed within each group.\n\nLet's group the iris data by Species and calculate the same summary statistics as before:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group the data by Species and then summarise [1, 9]\nmy_data %>%\n  group_by(Species) %>%\n  summarise(\n    count = n(), # Count the number of rows in each group [7, 8]\n    mean_sep_length = mean(Sepal.Length), # Calculate the mean of Sepal.Length for each species [1]\n    mean_pet_length = mean(Petal.Length)  # Calculate the mean of Petal.Length for each species [1]\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 Ã— 4\n  Species    count mean_sep_length mean_pet_length\n  <fct>      <int>           <dbl>           <dbl>\n1 setosa        50            5.01            1.46\n2 versicolor    50            5.94            4.26\n3 virginica     50            6.59            5.55\n```\n\n\n:::\n:::\n\n\n\nWe can also group by multiple variables: Let's use the `ToothGrowth` dataset:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Display the head of the ToothGrowth dataset\nhead(ToothGrowth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   len supp dose\n1  4.2   VC  0.5\n2 11.5   VC  0.5\n3  7.3   VC  0.5\n4  5.8   VC  0.5\n5  6.4   VC  0.5\n6 10.0   VC  0.5\n```\n\n\n:::\n:::\n\n\n\nNow, let's group by supp and dose and calculate the number of observations, mean, and standard deviation of len:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group by two variables and calculate summaries [1]\nToothGrowth %>%\n  group_by(supp, dose) %>%\n  summarise(\n    n = n(), # Count observations in each group [7]\n    mean_length = mean(len), # Calculate the mean of len [10]\n    sd_length = sd(len)      # Calculate the standard deviation of len [10]\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'supp'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 5\n# Groups:   supp [2]\n  supp   dose     n mean_length sd_length\n  <fct> <dbl> <int>       <dbl>     <dbl>\n1 OJ      0.5    10       13.2       4.46\n2 OJ      1      10       22.7       3.91\n3 OJ      2      10       26.1       2.66\n4 VC      0.5    10        7.98      2.75\n5 VC      1      10       16.8       2.52\n6 VC      2      10       26.1       4.80\n```\n\n\n:::\n:::\n\n\n\n## Summarising Multiple Variables\n\n`dplyr` provides several functions to summarise multiple variables efficiently:\n\nâ€¢ `summarise_all()`: Applies a summary function to every column in the data frame.\n\nâ€¢ `summarise_at()`: Applies summary functions to specific columns selected using a character vector.\n\nâ€¢ `summarise_if()`: Applies summary functions to columns selected with a predicate function that returns `TRUE`. For example, we can summarise only numeric columns:\n\nThe simplified formats for these functions are:\n\nâ€¢ `summarise_all(.tbl, .funs, ...)`\n\nâ€¢ `summarise_if(.tbl, .predicate, .funs, ...)`\n\nâ€¢ `summarise_at(.tbl, .vars, .funs, ...)`\n\nWhere `.funs` can be a function name or a list of function calls, and ... allows for additional arguments to the functions (e.g., `na.rm = TRUE`).\n\n## Useful Statistical Summary Functions\n\n`dplyr` works well with various R functions that compute statistical summaries:\n\nâ€¢ Measures of centrality: `mean()`,` median()`;\n\nâ€¢ Measures of variation: `sd()` (standard deviation), `IQR()` (interquartile range) , `range()`(range of the data);\n\nâ€¢ Measures of rank: `min()` (minimum value), `max()` (maximum value), `quantile()`; \n\nâ€¢ Counts: `n()` (the number of elements), `sum(!is.na(x))` (count non-missing values), `n_distinct()` (count the number of unique values).\n\nâ€¢ Counts and proportions of logical values: `sum(x > 10)` (count the number of elements where x > 10), `mean(y == 0)` (proportion of elements where y = 0).\n\n## Frequency Tables\n\nFor quickly obtaining frequency tables, `dplyr` provides the `count()` and `tally()` functions, which are synonymous.\n\nUsing the *penguins* dataset:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the penguins dataset [6]\nlibrary(palmerpenguins)\npenguins <- as_tibble(palmerpenguins::penguins)\npenguins\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 344 Ã— 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# â„¹ 334 more rows\n# â„¹ 2 more variables: sex <fct>, year <int>\n```\n\n\n:::\n:::\n\n\n\nWe can get a frequency table of the *species* column:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get a frequency table using tally\npenguins %>%\n  group_by(species) %>%\n  tally()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 Ã— 2\n  species       n\n  <fct>     <int>\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n```\n\n\n:::\n:::\n\n\n\nOr equivalently:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get a frequency table using count\npenguins %>%\n  count(species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 Ã— 2\n  species       n\n  <fct>     <int>\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n```\n\n\n:::\n:::\n\n\n\nWe can also group by multiple columns to get more detailed frequency tables:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get a frequency table with multiple grouping variables\npenguins %>%\n  count(species, island)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 Ã— 3\n  species   island        n\n  <fct>     <fct>     <int>\n1 Adelie    Biscoe       44\n2 Adelie    Dream        56\n3 Adelie    Torgersen    52\n4 Chinstrap Dream        68\n5 Gentoo    Biscoe      124\n```\n\n\n:::\n:::\n\n\n\n## Adding Summary Statistics as New Columns\n\nWhile `summarise()` collapses the data frame to summary rows, `mutate()` can be used in conjunction with `group_by()` to add summary statistics as new columns to the original data frame.\n\nFor example, to add the mean bill_length_mm for each island16 :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group by island and add the mean bill length as a new column [19]\npenguins %>%\n  drop_na(bill_length_mm) %>% # Remove rows with NA in bill_length_mm\n  group_by(island) %>%\n  mutate(mean_bill_length_island = mean(bill_length_mm)) %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 9\n# Groups:   island [1]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           36.7          19.3               193        3450\n5 Adelie  Torgersen           39.3          20.6               190        3650\n6 Adelie  Torgersen           38.9          17.8               181        3625\n# â„¹ 3 more variables: sex <fct>, year <int>, mean_bill_length_island <dbl>\n```\n\n\n:::\n:::\n\n\n\nRemember to `ungroup()` the data frame if you want subsequent operations to be performed on the entire dataset rather than by groups.\n\n## Conclusion\n\nThe `dplyr` package in the tidyverse offers a powerful and flexible set of tools for data summarisation in R. By combining functions like `group_by()` and `summarise()` (along with its variants `summarise_all()`, `summarise_at()`, `summarise_if()`) with various statistical summary functions, you can efficiently generate insightful summaries of your data, both for entire datasets and for specific groups. Functions like `count()` and `tally()` provide convenient ways to create frequency tables. These capabilities make dplyr an essential package for data analysis and exploration in R.\n\n# Exercise\nApproximate time: 60 min\n\n\n\n## Exploring Penguin Data with dplyr Summaries\n\nObjective: To practice using the dplyr package in R to calculate and explore summary statistics of the penguins dataset, both for the entire dataset and for specific groups.\n\nRequired Packages: `dplyr` and `palmerpenguins.` \n\n:::callout-warning\n\nRemember that you must use `install.package()` fucntion to intall R packages\n\n\n:::\n\nSteps:\n\n1. Load the necessary packages and the penguins dataset:\n\n2. Calculate basic summary statistics for the entire dataset:\n\n  - Find the average bill length (in mm) for all penguins, handling missing values.\n  - Calculate the minimum and maximum flipper length (in mm) for all penguins. \n  - Find the number of observations in the entire dataset using n().\n\n3. Calculate summary statistics grouped by a single variable (e.g., species):\n\n  - Find the average body mass (in kg) for each penguin species. Remember to convert grams to kilograms by dividing by 1000.\n  - For each species, calculate the average and standard deviation of bill depth (in mm).\n  \n4. Calculate summary statistics grouped by multiple variables (e.g., species and island):\n\n  - Determine the number of penguins of each species found on each island using count() or tally().\n  \n  - Calculate the average flipper length for each combination of species and sex.\n\n5. Use summarise_at() and summarise_if() to summarise multiple columns:\n\n  - Calculate the mean of bill_length_mm and bill_depth_mm for each island using summarise_at().\n  - Calculate the mean of all numeric columns for each species using summarise_if().\n\n6. Explore frequency tables:\n\n  - Create a frequency table showing the number of penguins for each species.\n  \n  - Create a frequency table showing the number of penguins for each combination of island and sex.\n\n7. Add summary statistics as a new column using mutate():\n\n  - Group the data by species and then add a new column showing the average bill length for that species to each row. Remember to ungroup() if needed for subsequent operations on the entire dataset.\n\n### Further Exploration (Challenges):\n\nâ€¢ Calculate the range (maximum - minimum) of body mass for each species.\n\nâ€¢ Find the median flipper length for each island.\n\nâ€¢ Determine the proportion of male and female penguins within each species. (Hint: You might need to combine group_by(), count(), and mutate() to calculate proportions).\n\nâ€¢ Group the data by island and then find the species with the longest average bill length on each island. (This might involve multiple steps).\n\nThis exercise will provide practical experience in using dplyr's powerful functions for data summarisation with the penguins dataset. Remember to refer to the help documentation (e.g., ?summarise) if you need more information on specific functions.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}